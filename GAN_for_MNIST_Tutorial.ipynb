{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrUqXYEepD0o"
   },
   "source": [
    "#### <b>GAN 실습</b>\n",
    "\n",
    "* 논문 제목: Generative Adversarial Networks <b>(NIPS 2014)</b>\n",
    "* 가장 기본적인 GAN 모델을 학습해보는 실습을 진행합니다.\n",
    "* 학습 데이터셋: <b>MNIST</b> (1 X 28 X 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEx96DYOpdAK"
   },
   "source": [
    "#### <b>필요한 라이브러리 불러오기</b>\n",
    "\n",
    "* 실습을 위한 PyTorch 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CiRb7M3naHyo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # 여러 model 사용\n",
    "\n",
    "from torchvision import datasets  # MNIST 불러오기\n",
    "import torchvision.transforms as transforms # 이미지 변환\n",
    "from torchvision.utils import save_image # output image 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tp4hbA95pihv"
   },
   "source": [
    "#### <b>생성자(Generator) 및 판별자(Discriminator) 모델 정의</b>  \n",
    "- Generator)  \n",
    "  1) block : batch_norm -> Leaky_ReLu  \n",
    "  2) model : block 4번(latent_dim -> 1024) -> linear -> tanh  \n",
    "  3) forward : model -> view(vector -> tensor)  \n",
    "  \n",
    "  \n",
    "- Discriminator)  \n",
    "  1) model : linear -> leaky_ReLu 2번 -> linear (28x28x1 -> 1) -> sigmoid  \n",
    "  2) forward : flattend 정의 -> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Hj5al6cTZES1"
   },
   "outputs": [],
   "source": [
    "latent_dim = 100 # z (batch_size,100)\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__() # super: 상속\n",
    "\n",
    "        # 하나의 블록(block) 정의\n",
    "        def block(input_dim, output_dim, normalize=True):\n",
    "            layers = [nn.Linear(input_dim, output_dim)]\n",
    "            if normalize:\n",
    "                # 배치 정규화(batch normalization) 수행(차원 동일)\n",
    "                layers.append(nn.BatchNorm1d(output_dim, 0.8)) # momentum = 0.8\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True)) # negative_slope = 0.2 (x 증가 시 y 감소)\n",
    "            return layers\n",
    "\n",
    "        # 생성자 모델은 연속적인 여러 개의 블록을 가짐\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, 1 * 28 * 28), # linear -> vector\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        # 데이터가 1*28*28로 vector 형태이므로 view를 통해 tensor로 변형\n",
    "        img = img.view(img.size(0), 1, 28, 28) # size(0): tensor row / view = reshape: tensor 변형\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "M_kvtvOhaLX6"
   },
   "outputs": [],
   "source": [
    "# 판별자(Discriminator) 클래스 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 * 28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        output = self.model(flattened)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOilX0rBqJXn"
   },
   "source": [
    "#### <b>학습 데이터셋 불러오기</b>\n",
    "\n",
    "* 학습을 위해 MNIST 데이터셋을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HrhXIwtAqM7H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokyoung/anaconda3/envs/bkseo/lib/python3.6/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370193460/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n",
    "# 다운받은 dataset을 dataloader를 통해 모델에 맞는 형식으로 변형\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4) # num_workers: CPU 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K54Z7PNIqTkO"
   },
   "source": [
    "#### <b>모델 학습 및 샘플링</b>\n",
    "\n",
    "* 학습을 위해 생성자와 판별자 모델을 초기화합니다.\n",
    "* 적절한 하이퍼 파라미터를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tBZf0BmBaN7l"
   },
   "outputs": [],
   "source": [
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss.cuda()\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0002\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9ThAQIOt-74"
   },
   "source": [
    "* 모델을 학습하면서 주기적으로 샘플링하여 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srQI5xI6ar-X",
    "outputId": "0bd2c30f-245a-4dea-8660-5a4c927de52e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.509063] [G loss: 0.982813] [Elapsed time: 5.40s]\n",
      "[Epoch 1/200] [D loss: 0.264311] [G loss: 1.396916] [Elapsed time: 10.53s]\n",
      "[Epoch 2/200] [D loss: 0.879870] [G loss: 3.039866] [Elapsed time: 15.56s]\n",
      "[Epoch 3/200] [D loss: 0.329299] [G loss: 1.167551] [Elapsed time: 20.68s]\n",
      "[Epoch 4/200] [D loss: 0.357042] [G loss: 2.285191] [Elapsed time: 25.69s]\n",
      "[Epoch 5/200] [D loss: 0.204072] [G loss: 1.616619] [Elapsed time: 30.53s]\n",
      "[Epoch 6/200] [D loss: 0.483739] [G loss: 2.656426] [Elapsed time: 35.40s]\n",
      "[Epoch 7/200] [D loss: 0.431194] [G loss: 2.762256] [Elapsed time: 40.76s]\n",
      "[Epoch 8/200] [D loss: 0.233607] [G loss: 1.610332] [Elapsed time: 45.78s]\n",
      "[Epoch 9/200] [D loss: 0.466672] [G loss: 0.653455] [Elapsed time: 51.04s]\n",
      "[Epoch 10/200] [D loss: 0.268835] [G loss: 1.851025] [Elapsed time: 56.04s]\n",
      "[Epoch 11/200] [D loss: 0.198230] [G loss: 1.953436] [Elapsed time: 61.89s]\n",
      "[Epoch 12/200] [D loss: 0.238519] [G loss: 1.264987] [Elapsed time: 66.64s]\n",
      "[Epoch 13/200] [D loss: 0.345266] [G loss: 3.425486] [Elapsed time: 71.55s]\n",
      "[Epoch 14/200] [D loss: 0.230483] [G loss: 2.152951] [Elapsed time: 76.47s]\n",
      "[Epoch 15/200] [D loss: 0.207192] [G loss: 1.963118] [Elapsed time: 81.29s]\n",
      "[Epoch 16/200] [D loss: 0.234400] [G loss: 2.010158] [Elapsed time: 86.16s]\n",
      "[Epoch 17/200] [D loss: 0.169042] [G loss: 2.317133] [Elapsed time: 91.10s]\n",
      "[Epoch 18/200] [D loss: 0.165465] [G loss: 4.031742] [Elapsed time: 96.04s]\n",
      "[Epoch 19/200] [D loss: 0.205295] [G loss: 2.588764] [Elapsed time: 100.94s]\n",
      "[Epoch 20/200] [D loss: 0.143815] [G loss: 2.005840] [Elapsed time: 105.84s]\n",
      "[Epoch 21/200] [D loss: 0.150034] [G loss: 2.481765] [Elapsed time: 110.48s]\n",
      "[Epoch 22/200] [D loss: 0.174996] [G loss: 2.619570] [Elapsed time: 115.40s]\n",
      "[Epoch 23/200] [D loss: 0.226436] [G loss: 3.959306] [Elapsed time: 120.28s]\n",
      "[Epoch 24/200] [D loss: 0.175503] [G loss: 3.310195] [Elapsed time: 125.19s]\n",
      "[Epoch 25/200] [D loss: 0.208562] [G loss: 4.215359] [Elapsed time: 130.07s]\n",
      "[Epoch 26/200] [D loss: 0.223352] [G loss: 1.333776] [Elapsed time: 134.92s]\n",
      "[Epoch 27/200] [D loss: 0.165842] [G loss: 2.124145] [Elapsed time: 139.61s]\n",
      "[Epoch 28/200] [D loss: 0.306162] [G loss: 1.093309] [Elapsed time: 144.25s]\n",
      "[Epoch 29/200] [D loss: 0.108126] [G loss: 2.598346] [Elapsed time: 149.13s]\n",
      "[Epoch 30/200] [D loss: 0.138726] [G loss: 2.070623] [Elapsed time: 154.03s]\n",
      "[Epoch 31/200] [D loss: 0.144127] [G loss: 2.328059] [Elapsed time: 159.00s]\n",
      "[Epoch 32/200] [D loss: 0.440942] [G loss: 6.032146] [Elapsed time: 163.78s]\n",
      "[Epoch 33/200] [D loss: 0.190179] [G loss: 3.492393] [Elapsed time: 168.66s]\n",
      "[Epoch 34/200] [D loss: 0.441984] [G loss: 0.863698] [Elapsed time: 173.60s]\n",
      "[Epoch 35/200] [D loss: 0.108639] [G loss: 6.372559] [Elapsed time: 178.53s]\n",
      "[Epoch 36/200] [D loss: 0.100583] [G loss: 2.668889] [Elapsed time: 183.45s]\n",
      "[Epoch 37/200] [D loss: 0.179831] [G loss: 1.544924] [Elapsed time: 188.34s]\n",
      "[Epoch 38/200] [D loss: 0.140175] [G loss: 1.898881] [Elapsed time: 193.29s]\n",
      "[Epoch 39/200] [D loss: 0.225387] [G loss: 4.262527] [Elapsed time: 198.14s]\n",
      "[Epoch 40/200] [D loss: 0.221498] [G loss: 3.304640] [Elapsed time: 202.97s]\n",
      "[Epoch 41/200] [D loss: 0.167692] [G loss: 1.998237] [Elapsed time: 207.84s]\n",
      "[Epoch 42/200] [D loss: 0.184607] [G loss: 2.716736] [Elapsed time: 212.72s]\n",
      "[Epoch 43/200] [D loss: 0.169489] [G loss: 1.908442] [Elapsed time: 217.60s]\n",
      "[Epoch 44/200] [D loss: 0.128796] [G loss: 2.135871] [Elapsed time: 222.56s]\n",
      "[Epoch 45/200] [D loss: 0.089138] [G loss: 2.409878] [Elapsed time: 228.03s]\n",
      "[Epoch 46/200] [D loss: 0.171451] [G loss: 2.024206] [Elapsed time: 233.16s]\n",
      "[Epoch 47/200] [D loss: 0.214960] [G loss: 3.636269] [Elapsed time: 238.03s]\n",
      "[Epoch 48/200] [D loss: 0.129022] [G loss: 3.018821] [Elapsed time: 242.94s]\n",
      "[Epoch 49/200] [D loss: 0.205504] [G loss: 2.145105] [Elapsed time: 248.05s]\n",
      "[Epoch 50/200] [D loss: 0.269607] [G loss: 3.114351] [Elapsed time: 253.35s]\n",
      "[Epoch 51/200] [D loss: 0.490817] [G loss: 6.793775] [Elapsed time: 258.02s]\n",
      "[Epoch 52/200] [D loss: 0.166409] [G loss: 2.363358] [Elapsed time: 262.97s]\n",
      "[Epoch 53/200] [D loss: 0.078194] [G loss: 3.985923] [Elapsed time: 267.98s]\n",
      "[Epoch 54/200] [D loss: 0.105659] [G loss: 2.382058] [Elapsed time: 273.31s]\n",
      "[Epoch 55/200] [D loss: 0.062585] [G loss: 3.210253] [Elapsed time: 278.25s]\n",
      "[Epoch 56/200] [D loss: 0.197092] [G loss: 3.117397] [Elapsed time: 283.14s]\n",
      "[Epoch 57/200] [D loss: 0.061623] [G loss: 3.632224] [Elapsed time: 288.00s]\n",
      "[Epoch 58/200] [D loss: 0.183403] [G loss: 1.908950] [Elapsed time: 293.02s]\n",
      "[Epoch 59/200] [D loss: 0.584578] [G loss: 7.677469] [Elapsed time: 298.32s]\n",
      "[Epoch 60/200] [D loss: 0.158638] [G loss: 3.081200] [Elapsed time: 303.20s]\n",
      "[Epoch 61/200] [D loss: 0.120336] [G loss: 4.196554] [Elapsed time: 307.86s]\n",
      "[Epoch 62/200] [D loss: 0.293155] [G loss: 5.539636] [Elapsed time: 312.94s]\n",
      "[Epoch 63/200] [D loss: 0.101861] [G loss: 2.951134] [Elapsed time: 317.64s]\n",
      "[Epoch 64/200] [D loss: 0.126421] [G loss: 2.637434] [Elapsed time: 322.20s]\n",
      "[Epoch 65/200] [D loss: 0.074823] [G loss: 2.951828] [Elapsed time: 327.21s]\n",
      "[Epoch 66/200] [D loss: 0.204979] [G loss: 3.029432] [Elapsed time: 332.45s]\n",
      "[Epoch 67/200] [D loss: 0.270220] [G loss: 1.384221] [Elapsed time: 338.14s]\n",
      "[Epoch 68/200] [D loss: 0.094238] [G loss: 3.013052] [Elapsed time: 343.05s]\n",
      "[Epoch 69/200] [D loss: 0.156876] [G loss: 2.167346] [Elapsed time: 347.94s]\n",
      "[Epoch 70/200] [D loss: 0.263572] [G loss: 4.062404] [Elapsed time: 352.91s]\n",
      "[Epoch 71/200] [D loss: 0.156146] [G loss: 2.703563] [Elapsed time: 357.79s]\n",
      "[Epoch 72/200] [D loss: 0.107723] [G loss: 3.180532] [Elapsed time: 362.76s]\n",
      "[Epoch 73/200] [D loss: 0.135112] [G loss: 5.740563] [Elapsed time: 367.73s]\n",
      "[Epoch 74/200] [D loss: 0.097584] [G loss: 2.670241] [Elapsed time: 372.57s]\n",
      "[Epoch 75/200] [D loss: 0.133553] [G loss: 6.506368] [Elapsed time: 377.51s]\n",
      "[Epoch 76/200] [D loss: 0.111583] [G loss: 3.861235] [Elapsed time: 382.45s]\n",
      "[Epoch 77/200] [D loss: 0.166447] [G loss: 2.075149] [Elapsed time: 387.37s]\n",
      "[Epoch 78/200] [D loss: 0.111379] [G loss: 3.161737] [Elapsed time: 392.27s]\n",
      "[Epoch 79/200] [D loss: 0.108538] [G loss: 2.657716] [Elapsed time: 397.27s]\n",
      "[Epoch 80/200] [D loss: 0.184225] [G loss: 1.917665] [Elapsed time: 402.03s]\n",
      "[Epoch 81/200] [D loss: 0.115127] [G loss: 3.768301] [Elapsed time: 406.56s]\n",
      "[Epoch 82/200] [D loss: 0.188083] [G loss: 2.299863] [Elapsed time: 411.12s]\n",
      "[Epoch 83/200] [D loss: 0.104895] [G loss: 4.026196] [Elapsed time: 415.81s]\n",
      "[Epoch 84/200] [D loss: 0.174938] [G loss: 1.771754] [Elapsed time: 420.74s]\n",
      "[Epoch 85/200] [D loss: 0.192583] [G loss: 1.672408] [Elapsed time: 425.63s]\n",
      "[Epoch 86/200] [D loss: 0.152805] [G loss: 1.761214] [Elapsed time: 430.47s]\n",
      "[Epoch 87/200] [D loss: 0.432167] [G loss: 7.218254] [Elapsed time: 435.14s]\n",
      "[Epoch 88/200] [D loss: 0.164296] [G loss: 2.652505] [Elapsed time: 440.02s]\n",
      "[Epoch 89/200] [D loss: 0.135430] [G loss: 4.078967] [Elapsed time: 444.98s]\n",
      "[Epoch 90/200] [D loss: 0.137960] [G loss: 3.211479] [Elapsed time: 449.90s]\n",
      "[Epoch 91/200] [D loss: 0.214915] [G loss: 1.786762] [Elapsed time: 454.76s]\n",
      "[Epoch 92/200] [D loss: 0.231236] [G loss: 3.491985] [Elapsed time: 459.54s]\n",
      "[Epoch 93/200] [D loss: 0.143320] [G loss: 3.759210] [Elapsed time: 464.32s]\n",
      "[Epoch 94/200] [D loss: 0.132551] [G loss: 2.913526] [Elapsed time: 469.20s]\n",
      "[Epoch 95/200] [D loss: 0.195843] [G loss: 2.510368] [Elapsed time: 474.05s]\n",
      "[Epoch 96/200] [D loss: 0.233462] [G loss: 2.390774] [Elapsed time: 478.91s]\n",
      "[Epoch 97/200] [D loss: 0.083652] [G loss: 3.438086] [Elapsed time: 483.77s]\n",
      "[Epoch 98/200] [D loss: 0.129708] [G loss: 2.615591] [Elapsed time: 488.62s]\n",
      "[Epoch 99/200] [D loss: 0.125601] [G loss: 3.980886] [Elapsed time: 493.57s]\n",
      "[Epoch 100/200] [D loss: 0.140394] [G loss: 3.325079] [Elapsed time: 498.47s]\n",
      "[Epoch 101/200] [D loss: 0.170053] [G loss: 2.257867] [Elapsed time: 503.34s]\n",
      "[Epoch 102/200] [D loss: 0.138139] [G loss: 5.140325] [Elapsed time: 508.26s]\n",
      "[Epoch 103/200] [D loss: 0.099755] [G loss: 3.218338] [Elapsed time: 513.21s]\n",
      "[Epoch 104/200] [D loss: 0.192480] [G loss: 3.160420] [Elapsed time: 518.14s]\n",
      "[Epoch 105/200] [D loss: 0.130245] [G loss: 2.822416] [Elapsed time: 523.07s]\n",
      "[Epoch 106/200] [D loss: 0.187258] [G loss: 2.924688] [Elapsed time: 528.02s]\n",
      "[Epoch 107/200] [D loss: 0.116444] [G loss: 4.551278] [Elapsed time: 532.90s]\n",
      "[Epoch 108/200] [D loss: 0.174886] [G loss: 2.896364] [Elapsed time: 537.77s]\n",
      "[Epoch 109/200] [D loss: 0.164582] [G loss: 3.226306] [Elapsed time: 542.70s]\n",
      "[Epoch 110/200] [D loss: 0.141442] [G loss: 2.854478] [Elapsed time: 547.59s]\n",
      "[Epoch 111/200] [D loss: 0.349158] [G loss: 5.058434] [Elapsed time: 552.51s]\n",
      "[Epoch 112/200] [D loss: 0.080950] [G loss: 3.998558] [Elapsed time: 557.42s]\n",
      "[Epoch 113/200] [D loss: 0.237514] [G loss: 5.341199] [Elapsed time: 562.29s]\n",
      "[Epoch 114/200] [D loss: 0.155816] [G loss: 1.960277] [Elapsed time: 567.25s]\n",
      "[Epoch 115/200] [D loss: 0.144098] [G loss: 2.477272] [Elapsed time: 572.14s]\n",
      "[Epoch 116/200] [D loss: 0.073617] [G loss: 3.440955] [Elapsed time: 577.02s]\n",
      "[Epoch 117/200] [D loss: 0.308024] [G loss: 5.209948] [Elapsed time: 581.92s]\n",
      "[Epoch 118/200] [D loss: 0.403814] [G loss: 2.320539] [Elapsed time: 586.88s]\n",
      "[Epoch 119/200] [D loss: 0.249270] [G loss: 1.611105] [Elapsed time: 592.03s]\n",
      "[Epoch 120/200] [D loss: 0.121101] [G loss: 3.168840] [Elapsed time: 597.34s]\n",
      "[Epoch 121/200] [D loss: 0.205249] [G loss: 1.712553] [Elapsed time: 602.30s]\n",
      "[Epoch 122/200] [D loss: 0.177404] [G loss: 2.687511] [Elapsed time: 607.25s]\n",
      "[Epoch 123/200] [D loss: 0.104709] [G loss: 3.193786] [Elapsed time: 612.50s]\n",
      "[Epoch 124/200] [D loss: 0.196070] [G loss: 2.611618] [Elapsed time: 617.41s]\n",
      "[Epoch 125/200] [D loss: 0.107347] [G loss: 1.983643] [Elapsed time: 622.23s]\n",
      "[Epoch 126/200] [D loss: 0.219513] [G loss: 2.512711] [Elapsed time: 627.10s]\n",
      "[Epoch 127/200] [D loss: 0.060598] [G loss: 3.285610] [Elapsed time: 632.00s]\n",
      "[Epoch 128/200] [D loss: 0.091517] [G loss: 3.203790] [Elapsed time: 636.97s]\n",
      "[Epoch 129/200] [D loss: 0.143125] [G loss: 2.393030] [Elapsed time: 641.89s]\n",
      "[Epoch 130/200] [D loss: 0.287341] [G loss: 1.160196] [Elapsed time: 646.90s]\n",
      "[Epoch 131/200] [D loss: 0.125809] [G loss: 2.823394] [Elapsed time: 652.23s]\n",
      "[Epoch 132/200] [D loss: 0.183377] [G loss: 3.276781] [Elapsed time: 657.39s]\n",
      "[Epoch 133/200] [D loss: 0.099116] [G loss: 3.421639] [Elapsed time: 662.52s]\n",
      "[Epoch 134/200] [D loss: 0.198741] [G loss: 4.288795] [Elapsed time: 667.35s]\n",
      "[Epoch 135/200] [D loss: 0.306800] [G loss: 1.908499] [Elapsed time: 672.03s]\n",
      "[Epoch 136/200] [D loss: 0.111065] [G loss: 2.344631] [Elapsed time: 676.88s]\n",
      "[Epoch 137/200] [D loss: 0.153697] [G loss: 2.845939] [Elapsed time: 681.90s]\n",
      "[Epoch 138/200] [D loss: 0.232772] [G loss: 2.673795] [Elapsed time: 686.73s]\n",
      "[Epoch 139/200] [D loss: 0.272697] [G loss: 1.919671] [Elapsed time: 692.21s]\n",
      "[Epoch 140/200] [D loss: 0.113764] [G loss: 3.278577] [Elapsed time: 697.69s]\n",
      "[Epoch 141/200] [D loss: 0.183025] [G loss: 2.005012] [Elapsed time: 703.09s]\n",
      "[Epoch 142/200] [D loss: 0.147594] [G loss: 2.823143] [Elapsed time: 708.38s]\n",
      "[Epoch 143/200] [D loss: 0.258114] [G loss: 5.133888] [Elapsed time: 713.16s]\n",
      "[Epoch 144/200] [D loss: 0.212342] [G loss: 3.162717] [Elapsed time: 718.16s]\n",
      "[Epoch 145/200] [D loss: 0.164079] [G loss: 4.004219] [Elapsed time: 723.16s]\n",
      "[Epoch 146/200] [D loss: 0.132792] [G loss: 6.688209] [Elapsed time: 728.15s]\n",
      "[Epoch 147/200] [D loss: 0.246253] [G loss: 2.136658] [Elapsed time: 733.37s]\n",
      "[Epoch 148/200] [D loss: 0.191728] [G loss: 4.016930] [Elapsed time: 738.13s]\n",
      "[Epoch 149/200] [D loss: 0.297952] [G loss: 4.962207] [Elapsed time: 743.17s]\n",
      "[Epoch 150/200] [D loss: 0.149908] [G loss: 3.759831] [Elapsed time: 748.41s]\n",
      "[Epoch 151/200] [D loss: 0.325817] [G loss: 1.578833] [Elapsed time: 753.41s]\n",
      "[Epoch 152/200] [D loss: 0.263116] [G loss: 4.046777] [Elapsed time: 758.62s]\n",
      "[Epoch 153/200] [D loss: 0.120199] [G loss: 3.531730] [Elapsed time: 764.69s]\n",
      "[Epoch 154/200] [D loss: 0.133154] [G loss: 3.771623] [Elapsed time: 770.30s]\n",
      "[Epoch 155/200] [D loss: 0.187069] [G loss: 4.547414] [Elapsed time: 775.29s]\n",
      "[Epoch 156/200] [D loss: 0.087310] [G loss: 3.779364] [Elapsed time: 780.15s]\n",
      "[Epoch 157/200] [D loss: 0.095470] [G loss: 3.304911] [Elapsed time: 785.26s]\n",
      "[Epoch 158/200] [D loss: 0.147176] [G loss: 2.382860] [Elapsed time: 790.40s]\n",
      "[Epoch 159/200] [D loss: 0.138957] [G loss: 3.677613] [Elapsed time: 795.60s]\n",
      "[Epoch 160/200] [D loss: 0.109127] [G loss: 3.953993] [Elapsed time: 800.64s]\n",
      "[Epoch 161/200] [D loss: 0.102135] [G loss: 2.162387] [Elapsed time: 805.65s]\n",
      "[Epoch 162/200] [D loss: 0.121450] [G loss: 3.535714] [Elapsed time: 810.85s]\n",
      "[Epoch 163/200] [D loss: 0.183353] [G loss: 5.311819] [Elapsed time: 815.95s]\n",
      "[Epoch 164/200] [D loss: 0.134185] [G loss: 5.355221] [Elapsed time: 820.97s]\n",
      "[Epoch 165/200] [D loss: 0.218801] [G loss: 5.113406] [Elapsed time: 826.00s]\n",
      "[Epoch 166/200] [D loss: 0.181915] [G loss: 2.579146] [Elapsed time: 831.09s]\n",
      "[Epoch 167/200] [D loss: 0.130110] [G loss: 2.116060] [Elapsed time: 837.07s]\n",
      "[Epoch 168/200] [D loss: 0.179578] [G loss: 2.807710] [Elapsed time: 842.54s]\n",
      "[Epoch 169/200] [D loss: 0.108464] [G loss: 3.641238] [Elapsed time: 847.24s]\n",
      "[Epoch 170/200] [D loss: 0.159114] [G loss: 2.748014] [Elapsed time: 852.33s]\n",
      "[Epoch 171/200] [D loss: 0.360374] [G loss: 1.307963] [Elapsed time: 857.11s]\n",
      "[Epoch 172/200] [D loss: 0.117607] [G loss: 2.697987] [Elapsed time: 861.92s]\n",
      "[Epoch 173/200] [D loss: 0.065734] [G loss: 3.631832] [Elapsed time: 866.92s]\n",
      "[Epoch 174/200] [D loss: 0.082968] [G loss: 3.775619] [Elapsed time: 872.24s]\n",
      "[Epoch 175/200] [D loss: 0.066078] [G loss: 3.096632] [Elapsed time: 877.11s]\n",
      "[Epoch 176/200] [D loss: 0.193612] [G loss: 1.895501] [Elapsed time: 881.72s]\n",
      "[Epoch 177/200] [D loss: 0.131592] [G loss: 6.483236] [Elapsed time: 886.75s]\n",
      "[Epoch 178/200] [D loss: 0.237099] [G loss: 1.874820] [Elapsed time: 891.67s]\n",
      "[Epoch 179/200] [D loss: 0.092772] [G loss: 3.677793] [Elapsed time: 896.42s]\n",
      "[Epoch 180/200] [D loss: 0.056177] [G loss: 3.776714] [Elapsed time: 900.98s]\n",
      "[Epoch 181/200] [D loss: 0.166410] [G loss: 4.110306] [Elapsed time: 905.55s]\n",
      "[Epoch 182/200] [D loss: 0.147560] [G loss: 4.890657] [Elapsed time: 910.45s]\n",
      "[Epoch 183/200] [D loss: 0.139413] [G loss: 4.305681] [Elapsed time: 915.36s]\n",
      "[Epoch 184/200] [D loss: 0.107516] [G loss: 2.812224] [Elapsed time: 920.29s]\n",
      "[Epoch 185/200] [D loss: 0.042121] [G loss: 4.421093] [Elapsed time: 925.16s]\n",
      "[Epoch 186/200] [D loss: 0.117614] [G loss: 2.476466] [Elapsed time: 930.06s]\n",
      "[Epoch 187/200] [D loss: 0.242309] [G loss: 1.949344] [Elapsed time: 934.96s]\n",
      "[Epoch 188/200] [D loss: 0.148503] [G loss: 3.352914] [Elapsed time: 939.85s]\n",
      "[Epoch 189/200] [D loss: 0.105385] [G loss: 2.689176] [Elapsed time: 944.77s]\n",
      "[Epoch 190/200] [D loss: 0.122741] [G loss: 2.892843] [Elapsed time: 949.65s]\n",
      "[Epoch 191/200] [D loss: 0.237056] [G loss: 3.461079] [Elapsed time: 954.52s]\n",
      "[Epoch 192/200] [D loss: 0.088915] [G loss: 3.527960] [Elapsed time: 959.46s]\n",
      "[Epoch 193/200] [D loss: 0.189875] [G loss: 2.637212] [Elapsed time: 964.30s]\n",
      "[Epoch 194/200] [D loss: 0.149106] [G loss: 3.185054] [Elapsed time: 969.18s]\n",
      "[Epoch 195/200] [D loss: 0.147007] [G loss: 3.017432] [Elapsed time: 973.92s]\n",
      "[Epoch 196/200] [D loss: 0.139820] [G loss: 3.077703] [Elapsed time: 978.47s]\n",
      "[Epoch 197/200] [D loss: 0.165406] [G loss: 2.716666] [Elapsed time: 983.28s]\n",
      "[Epoch 198/200] [D loss: 0.152098] [G loss: 3.203838] [Elapsed time: 988.16s]\n",
      "[Epoch 199/200] [D loss: 0.269447] [G loss: 5.089713] [Elapsed time: 993.00s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 200 # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 2000 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.cuda()\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad() # epoch 반복 시 초기화\n",
    "\n",
    "        # 랜덤 노이즈(noise) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
    "            save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKhzqw6U8u-H"
   },
   "source": [
    "* 생성된 이미지 예시를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "FeC3eMGa8vc1",
    "outputId": "49201c7d-9673-4555-e4d5-e6e8d2eb214b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAACYCAIAAACXoLd2AAAnzElEQVR4nO1dd0BUV9af+96bPrShV6kCFoIFg26i2JJYoquiorhojKssGqNGo+YjJtE0O4omQU2Ca2yoG01cY1xjN7Ghoogo2CAygAgyfV79/ribl8kAw5v3Hlmzy+8vmHn3vDO3nHvuuadIJO1oRzueOphMJvt/AQD2/x48eJA35W7dujn5ViaT8absHA4/gQc0Go09KeEEJRLJ+fPnnXyLIIjz5qLwIJSWmEy0gyOioqLYv1tdNFKplP0bRVHnD9tTa3UC2uM/Ow9a+l0OXLnKpEqlYv/29PR0/rA9cfs+b8cfDy7PZhGnf6tr1AEuLVOOwDBMIIX/3X2hVUFhD/tuErfLEAS5cuWK1Wr9+uuv206xagsAAJqV25yEOYqi/fv359iVTd/kHDExMc1+rlKpUBR1TiogIEAqlfIYY5lMduzYMYZhzGaz/cbPHexLAQAIgpw8efL06dM4jtfW1iYkJLgqbyCCg4O7du3q8KFcLscwDL4OQRAURREEQRBEJpN5eHhERETYb6itwLlYgyPXqVOnnJycOXPmxMfHKxQKCbc11OwzsGswDFMoFOx0Y5+Uy+UpKSkIgmi1WgzD3NzcOL7LHiEhIfX19QzD0DQ9a9Ysjq3s30JRlE6nk8vlDMMUFBQwDAOp0TRNkiT8myAIpVLpEmNNgSAIsENgYOCIESOeffbZxMTEvXv3pqamRkdHS4RLLI1GM2DAgEePHpEkabVa4c8wGAyRkZFCDiSZmZlhYWFubm79+/cfMGDAsmXL8vLy6urq4ItIkjxy5IjFYsnLy+NHPzEx0Wq1MgxDEERcXJyrFBoaGsLCwvLy8k6cOAGHrSXU19f36tXLhUXTAjAMk8lkarV68+bNixcvLisrq6urM5vNixYtEr7TSzAM++qrr3Acp2kax/G9e/e+9dZbFEXRND1v3jx+NDUajclk+uabb2JiYgYNGnTu3Lnq6uqSkpIXXnihpqYGEsdxXK1W7969e9KkScXFxa6+AgAQGxtrMBgYhmlsbHRVjQIAmEym/v37Z2RkREVF+fr6xsTEEARBEERVVdWNGzcqKytfeeWVL7/88sKFC3DaGQwGgcoaAEClUr366qvp6ekajSY1NdVqtZIk+f777wsh+2+EhIRYrVaz2WwwGLZt2xYYGDhlyhSSJC0WC3cNwmE7OXXq1MmTJ8ePHz9lypR58+Z9++236enpKIqiKBoTE5Oamrpnz54dO3ZIJBK1Wl1WVsajgxAEiYiIIAiCpumamhpXZzQAICkpSdJkx4HbAfwQbmOTJk2iaZphGIPBsG7dOlf5tIdCoQgNDR07dqyfnx+GYRs3bqQoqqGhQahEBQAolcra2lqKomw2W2RkZOfOnT09PeGK0el0TZs0e1Z14OPixYtQaEyfPn306NGQadgQwzBvb++wsDAURVkjGQSPJfX+++/DgSwoKPDw8BBCzYGy/b+pqakURTEMg+N4RUWFq81ZoCjasWPHRYsWubu7q9XqwMBAuBnv3buXN6u/IjMzE0637du3d+jQIT4+Pj8/nyRJiqK8vb350VSr1RKJRK/XV1VVrV69Gmqt/v7+06ZNi46Ojo2NhatHuAbRr18/yPyIESN4WENa0tEcPvH29rbZbHAsx4wZw49VAICvr++WLVvi4+OlUqmbm9vcuXMJgjCbzQ4TmhOayh8EQaxWK1yRBEFQFAU5vnTpEg/lG9KH+ipcK3V1dRaLhSRJqP5VV1cnJyfL5XK4YgSKlI4dO8KB9PPzc6mhzWbj+HYEQYKCgiD/JEkKMZ4hCKJWq7Vabffu3b/99luj0UjT9AcffMBl/3IULyRJNn2oZ8+eR44cefTo0aefflpbW2s2mxmGYQ893OHm5gbpQ60dymdPT0+5XG42mymKslqtnp6eX3/99apVq4YNGwafdOkVDmAnn6t05HI5x7czDHPz5k0oVAAAQ4YM4cmrRELTtMlkMhgM9fX1/v7+dXV11dXVp06dIgiCN81mIJVKURTt3LmzwWCgKKpHjx5cWjkZbHhyQhBEoVAoFAqtVpuamlpXV3fs2LFevXoFBwc7b84FAwcOhGvF399fCB0ncHNzg4ueYZjy8nLhBBEEiY2NraysfPDgwdy5c+EB2gXQNM3lMY1GU19fX1ZWxl2uNjQ0cNEsAAB+fn5btmwJDg5WKBQajUa4uS4mJgZK7ISEBJeoLVmyhOOTkZGRcCApiqqqqmr1La1ueACA0NDQ3Nzc9PR01lTCFRyfRlF01apV165d69u3rwvUOdPHMOz48eNDhw718fFxiX5LSE9PpyiKJMnY2FjnPDT9lstxRSaTnTt3DopugiC6du3qMGV5zMXevXvn5+cvWrRIqVS2lbFeKpX+85//vHr1qnATRrPQarU2m62goACqtc3Cpd+m1WobGxtNJlNqampb3OH5+Piwxp3169ejKCpQ05ZKpdOmTZs+fXr37t35GXJbBwAgLi6usrLSZrMJXzFQm3Cgf+/ePZIkHaxFDgPg0kAqlUqLxaLX67ds2TJixAiX2nJ5uKysjB1IVxXjZhEUFHTy5MnMzEylUunSSfffj3I0fH/wwQcajWbXrl11dXU8OZVIAAB6vZ4dSFa3hvqO2Wxev369/fMOOptL+ieO49CinZSU5OHhwbFrrl+/zuVFAAB4kqYoqrq6+tGjR9wZaxYYho0aNerGjRtGoxEatAUSbB7PPvvsnTt3bt261fQKxiVgGLZr167Y2FiVSoUgCFSG3dzcsrOznzx5Ehoa6vC8kH0CQZDGxkaapvV6/YULF8TdcpRKJUEQDMM8fvxYFIK+vr4ff/xxTk5OS/LZCf8umB83bdpEEMTdu3dv3rzpMo92oChq2rRp48aNwzDs5s2bBoNh8+bNRUVFY8eONZvNDx8+dHheyFESQZAlS5asXbtWoVBcvnxZCNsOAAA8//zz8O/79++LQrNnz56nT5+2Wq1Wq7XZB5x0xW8GEkVRiqKafc7d3f38+fNyuXz//v3NGg1+pYhhzh9gGMZoNG7btm3ZsmUpKSlubm4PHjwICAgoLS0dMWKEuPKEJMlHjx5Bi+WyZcsEmhccMGzYMKjZdujQAUGQZjlv9nMAgAMnAAAvL6+UlJRjx46dOXPGCZ9s26ZEOKGgoMBisdy9e3fdunUcD4XNfs6a6KA5vnv37vn5+SqVysPDQy6XT58+3WXOWkNOTo7ZbK6qqgoKCuLR3Ik027x5MzxB/vjjj0FBQfwcVhAEkcvlSUlJNTU1DQ0Np0+fdn7QbJ2ykycGDBiQlpZ248aNAwcODBw4sCVTsv3nDlcNDmBPL/AeFTbneM20YcMGLo+JDgc1GwCQm5tL0/S1a9daPSc4eQDatpRKZXx8/KxZs9RqdbO+OezDggYyPDw8LCzs4cOHFEXhOM7J/4czpFJpaGjo4cOH4d1eU2ptdSgWjC+//JJhmCFDhrRk1A4ICOBOrX///uxURhBk4sSJfHhySRF1qWedH8MdSHEx8/8O49qlS5emH7IbipB5zO8S9Kmdyu1oRzucY/Xq1fb/OqzlZl062gjtYuR3gghOee343dCnTx8J553ZXkNpX0/taEcb4GlYWImJie7u7uy/8OAsnGy3bt1WrVrVFjFfol8fshdkfBqLNYQwLEQI3n333YULFz7zzDOi8AMBANixYwfDMKtWrRKR7IABAw4cOHD58uUvv/xSRLL2IQkuN1ar1c2qMxiGwRnHe6Rv3brF8Ulo4tm5c+eePXu4THPuLH3xxRdVVVU2m01EbwGZTFZTU8MwTE1NTWRkpCg0m8aWQJ9CrmhW4ECZJpVKPTw8MAzr3Lnza6+9lpWVJbpHiVqthneTGRkZBEHA25zw8HCx6KempkIbd1VVlYiiddu2bZAsTdOihGA6rEJBAtYB7u7u69evLygouHfvXn19vU6noyiKIIitW7cK7BGFQoEgSGBgYOfOnUeOHCmVSqVS6fjx43fu3Gk2m2maFmuuIAiC4zjsEd7O4E0RGxvb2NgIyVIUxW+bdBgkSG3ChAn2/4rAq1QqHTt2bG1trV6vb2hoOHv27KRJk5KTkwmCsNlsLntd/gIYccgwTG1t7aeffpqdnf3uu+9CB3MEQfbt2wcvEUU5tiIIEhISAgniOC6Kcw3EgQMH2IG0Wq3C9R1fX1/7kcMwjOdANnv5MG/ePKPROGvWrD59+sDg4aCgIIvFotPpeK8YVmJUVFRs3bq1urraYDAEBQV16tRp8eLFMKgR+u0Lx7hx4w4dOsQwTGVlJfR7FgVqtVqv17PeySNGjBCFrPhyFcaPDRs2zGKxGAyGpUuXwltDBEGMRiNJkleuXGnaiosecf/+fbiprFmzBn6ye/furKwsFEX//ve/T548mV/ARrMICAgwGo2wOxYsWCDivj5gwAA2+hXHceGKOkTTgRSFrKS0tBRuAP7+/nK5XCaTTZkyxWAwEATR1KWRI2iadnd3d7hSh+ETGo1mzpw5FEXB4EjhgDG5DMPo9frAwEBRaELMnj3bXq6IRZbNQgbnumgDGRMTQ5KkzWYzGAw4jsO/GYb54YcfeG8Jy5Yta2kSwMgmhmHECQqUSMrLyxmG2bFjx969ezndsHPGlStXmF/yCWRlZbm6IlsdITH1VYlEolarFy5cWFhYqNPpdu/eXVJScufOHZqmy8rKeGvb27Ztu3TpUtPPAQBsiJ0oao5UKq2pqcFx3MvLS1xrDjzpMgxjNpuvX7/OW+lrCXAIXXZFa3WeAgCgSunh4XHr1i2aplNSUnhzGRISQlHUn//8Z+iCBRdKRETEoEGDtm7dCiW5KEvnu+++gycl0e1n3bp1g3KvoqKiZ8+ePGaJk6UmaC0yDMMxrrOkpMRgMAjc261Wq9FoNJlMrNZH/wK4nwkhDuHu7m6xWGia3rRpk7gDCQC4efMmZNtkMj333HMiSmzGDi435j6htFptYWHhsWPHhLCOYdj06dN1Oh3MZsQC7r4Mwwg3oQUHBz958gTSbDUUy1UkJCSw86+oqEjE4Evmt+De8N/jx10Wq9Xq0NBQo9Ho/DHnHUeSZGFhYadOnSZOnFhSUkKSZFFR0dGjR2GGk44dOwqP0a2trVUqlQzDzJgx4/bt26KpDBKJRCLx9fWFP9BsNj969KihoUE4zXPnzonGJJdpO378eJqmW3WSd8lDVyaTTZgwwcPDY8+ePcuWLRNl9SgUCpj6QKxzuj3y8/Phijlx4kRWVhbvY5gDIM3k5GT+opWj/gkAOH/+PEmSERERLr+jBYLu7u5arXbv3r0vvvjiwYMHQ0JChJPVaDTZ2dkEQdTV1Yl1I2EPk8kEO3rixIli7b4OgyfmwaMp5HK5Tqczm82iXANJpdL4+PiEhIRHjx6dPn06JSVl8uTJoixHuVxuNBrbSF+F+UigdjZgwACxdl+mCUQh2zzc3NyMRqOQ4Eh7aDSa3Nzca9euwWgesQSURCJBEARenpw8eVIsmixgqBPUV/lkwGkBOI7DdCkijGKr6yw4ONhoNO7fv9/JMy6dqFAULSoqCgwMVKlUIiqWGIYVFxdbLJYVK1aIRZMFAAAOZElJibg+heKvxZb6dO7cudBK1+pocR/Oy5cvNzY2sqE8LvHZEry9vT/55JOsrKy2SLaLouh33313+/ZtsazkbQs2rtr+k5UrV1qt1srKymZnov3gccypCQCIj4//6quv2tTdS3TiYnmC/Wfg7+8PT8G5ublizfRevXqJQscB9lNQXEO5PWQy2dPgbvgbvPfee9wfbqu0Ie1oRzva0Q6R4GSbcXAhcCl5RnuwkfhwVSNgXXXaN+OnDlyOiQzDpKamtkrqqV1qDr/uv20WOvk9ly9fhsnjoY+rWPmj/lvhJNsHH2g0GiEWDQBAaGioyWTCMCw8PNzePWDz5s3isPgfQnZ2dlpa2qhRo9i+FuVqAUXRyspK12I/WgWCIPfv3zebzaNGjeJNxNvbOy0tbc2aNQ0NDRMmTKBp+uuvv/bw8FCpVL169WoLK0xxcbHJZHrttdfEpcwiLi7OarXW1tYyDKNUKjt06ICiqChdDwB49tln9Xo9SZJi7ikAgIqKCrPZ7FJ1CzbN/DPPPJOYmBgWFgYA6NChg7u7OywIJZFIfHx8unTpkp6eLvoWyNq4aZp2NbNWqx7SKIpu375906ZNNpvNZrM5JCFKSEjgw7EdFAoFzHL+008/CST1G6AoWlJSQtP0mTNneDSXy+UjR45UqVRxcXEBAQGs8Qxm8Z49e/bVq1dhzZSWwCNPrLe3NyvAxRVQQUFBtbW1BEHo9fopU6a8/fbbbHEEiUQCABgyZIiQeQkAOHr0KOS8d+/eInH9C+kffviBJMkFCxa41BDmLKuqqho6dKjDzuHn5zdp0iSYwXzy5Mmt3vAtXbrUpVcPHjyYHUge6ehaSiXWpUuXPn36FBQUrFy5MiQkxMH47OnpuXz58pqaGrlcztubQqlUsgF7IvvNAgCKiooMBgOP0i0XL15cu3atr68vm+YaJqLr0qULjKIFACxfvnz69OnibpOvvvoqq08NHz5cIDXof5ufn5+bmxsZGblkyRIHtRyuSJVKlZiYKOQGHkXRgIAAyDmO462ubNfuYtRqdceOHWUyWdPbj1Z7Pykp6Y033qirq2NjG4YNGxYREQFHkWEYFEVNJlNOTs727ds51jTmAjY7GwDApSTHzV5UMQzTr1+/MWPGAADCwsLOnTvHihAEQcLDwz/88MOjR4+eOXPmwoULRqORt+KanJx84MABiURCkmRcXJzzzKkuY+LEiTDE0KHKgKenJ7/7OYcSoElJSbW1tRs3bvT29rYfS/gMj/0GQRAYhAThJOc9d8TExFRUVOTm5gYHB3fp0oUdKh8fH5itmWEYkiRhARN+EddyuRwGrDEMc/XqVS5961rve3l5SSSSgoKCCxcu2H/+5MmTVj1jYe6e37wbQRxq5BQWFg4ePLixsTElJcX+tAqfIUmSezZQtiHrPQzD2bm3bQl3794lCGLUqFE+Pj5wIvr4+Mjl8tGjR7u5uV27dm3p0qUymSwwMHDgwIH8kisHBwdDb0Kapn/66Sfxk5vPnj2bpmkRPY6aAgCwaNGisLCwbt26iUJNr9fDqV1aWspRMjt/TC6Xl5WVffTRRxkZGcHBwZ6engEBAXPnzv3+++/ZvAqsQs5vv8/Pz6dp2mKxWCyWoKAgLm5prq3IgIAAGInPgznu2LVrV1RUVHFxsShaz+zZsyUSCUVRq1ev5si588eio6Ohq5hOp/Pw8AgODp40aVL37t0nTZpksVhgW9aHikdfAQDu3bsHADhy5EhaWlpNTY1Ykdv/Boqijx8/pijKpYrmTuDp6cnKSRiWBROH5ObmRkVFOehTvDOdnjp1imEYgiCef/554TMDABAdHV1WVnbx4sUxY8Zs2bIFsu3n5yeWsq3RaGAV2ldeeYVHJbnWgWGYyWR6/PgxD5WhWXdvpVIJS9fAGPeSkpL58+er1epZs2YNHToUAODp6QlrvEokEn5FbqCmCrUPV8++zVILDw9vaGiAtRdNJpPVaoXJq2EOC4H0IRYuXMgwDEVRe/fuFdHX91fAm4qzZ8+K6EAG07OgKDpjxoxVq1ZdvXp1wIABSqUyMDBQoVCsWbMG6oSw8Dk/+nCPJAjixRdf5M0nPGy8/PLLVVVVI0eOzMvLu3nzJqycyDvUq9m8G8OHD4d6r81mS0tLaxOPy6ioKIvFMnPmzLawa3t5eWVmZl64cEGtVsvlcujNTVHUwoUL7QfAVROdWq1my9dnZ2fzZk8qlWZkZFit1oqKirfeeksmk/n7+5vNZpvNBjV5sfD222/D8no5OTliBdg44uTJkzRNd+7cWUSaUVFRGo2mR48eBoOBpumGhoZu3brNmTOHDXfasWMHiqK8vS9lMhlrMX/y5AlvPgcNGqTT6exTd4wcOdJqtX722WfsOVKU+Q0DRqEi0hbe1RIAwM8//0xRlLhnj+zs7AULFrDnaJ1OB+t8w1F88uSJt7d30/wf3OlLpVK2uOOsWbN4cAjL5cJ6VXV1dQqFAsMwtVo9d+7cGzduDB8+XERPAFgFGZb4dZUs141HpVL5+fnBYro8+Gup1Ycffuju7v748eN169ZdvXrVy8urqqoKfjV27NgTJ05AwSixKzzjkkLPbueM6+mXINuwXO79+/fj4+MRBDl69GhOTk5AQEBVVdWQIUPUarVCoYDBN4BfaRw7dO/eHTo9Q7OOEFItYsaMGRRFXbt2rS30KLbUmVKpDAsL+8c//sF+JXC+R0ZGwrOd2WwWIqnc3d1LS0tLS0ufPHlSXFw8evRotVqNomjfvn3Dw8ODgoJa0kpcUgxnzJgBRVF6erqrHHJ9TWBgILSStEUJULi90zQNtYnRo0ezX7VUq4sjTCYTXCgmkwnHcd50jEbj8OHDT5w4UVdX5+Xl1blzZ5VK5e7u/uabbx48eBBmKWz2dOSSALtw4QLcBU6dOsWb1VYQFBS0cePG5ORkfls6W9jNJQhXH1jxCG0lQujAwkfw33379uXn5x89evT+/fvQ/2jo0KHCs+7K5fLMzMyoqCiBdP47AY0joqiU9kTUavXYsWPtw7L+wPFZXMBuHqI44/AYD3tD4B8FUqn0qYvzahbOa9k9zfjDzYl2tKMd7fgfx3+5utSOdrSjOfwxFOJ2cISHh0dqauorr7zSduP6xRdfMAzz6NEjUe5x1Gq1KF6QzhEeHv7kyZO1a9eK4k0yffr0Bw8eiJuB3RGDBw+2WCyPHz9uo3RBAIDs7Gyj0Wg0GgV2Ciz3odfrcRyPjY0Vi8OmAAB069btwoULBEEILBMNAIiKioKW55KSkjZ0WPTy8iorK6utrW2jgZRKpfX19ZWVlf/3f/8nkBQAQCaT1dXV0TTNJRaaN1QqVXFx8QcffJCZmSmcmlqthq6KOI6npaUJJ9g8/P39KYoym81tFFq9evVqaOYWxfrj6ekJb631en0b7QUIgly8eNFms9XX14vi9uHr6wuzTzIMc+TIEeEEm0d8fDxFUfX19W1x6AEAsBk0RZkoKIreu3ePoqjS0lLh1JqFj48PjuM4jh8+fFiUPpHL5WwZry1btnBs5fKLJ06cSJLkxYsXxfdjl0hQFIUXT9DjQThBiqJgXYo2GkipVDp//nwURc+cOZOdnc39Wt+JeLCvsLBt2zYRuGz29eXl5TRNN735FC64MAzbtGkTdNUR0aoO98g9e/aIRdAeUC9jGCYiIsKl5eiku1g/I4Zh1q9fLwabTeDv7w9FX1FRkT0rffr0CQsLc86fcwAA5s+fD7nfs2cPb28rB8hksoaGBoZhli9fLvpekJSUBMsiGI1Ge2VVqVTaFxV2Ff369WMHsri42P4r0bb5uLg46JaRkZEhru6AYVh1dTV0CZ88ebKIlKHPjog5qyFQFP3iiy8oiiJJct68eSISf+aZZ9g4wNu3b4tF9jcYOHAgTdMzZ84U/YidmJhIkqTJZGpoaPD09BTRxauiooJhmI4dO4pFEAJBkNu3b9M07evrq9VqRaTMVp6laXrIkCFc+eH+AgDACy+8AKMpzGYzLyZbxNSpU1EUvXz58sCBA41Go4jxR9988w3DMKJfCCclJUVERFRXV9fX19fX17vU1vnyvXLlChvHGR8fz5GmCwOJYdjrr78u+UVYcW/YKlQqFTxKf/XVV0VFRQI95xwAfXbEPVmjKHrs2DEURTUaDQ/t2nnvNTQ0sNOOIAiOW7sLA6nVaqFCZTAYuLfigpUrV0qlUsaupBL3tq3+TljGJTw8XKxtDEGQkSNHQo+6d955R3RPYqvVCgcSALBq1SpxiUskv9hcGhsbRTQAIgjy+uuvw8EzGAw+Pj7i6pYAgOPHj5MkOX/+fLEG8uWXX4aqu8lkagt37R49erCWHTZtf6vg2msw/Q9FUTt37hQlEh+CYRhoUzUYDKmpqUajUVw7A8Mwhw8fJggiISFBrCliNBphsFh4eLjIscQSiUQi0el0Dx8+hH+7ubk5r6Dm8o+SSqWwPie/NBUtAcMwaI6Cxtu2MIeeP38ex/GtW7eGhoYKp4YgSO/evc1mc2Njo7gBdSwwDHv8+DF7lDQYDFy6het4pqSkAABomq6srBTG56+Ijo4uLCyEuT3u3r3rkOFDLMAqJREREc7vxbh0FgCgsLDw+PHjEolkw4YNjY2NYjL6CyiKKisrY/lRqVRckvVwGkgURffv3w8AKCsrE0v0yWQyFEXDw8OhfbXt7msUCgUAQKvVxsTEOJkoXOZQp06dUBSFmkhlZWVbWJshJ3fv3mX/NZlMomVL6tq1K7RiDxw4UByKEolEItFqtTiOQwWq7fwN4uLiCIK4f/8+j4SEDvDx8Tl06BBJksXFxW0RzMQCnmqgaM3KyhJtO1uzZg2O4wRBCDEhNoVarX7w4AGM+xWRrAP8/f1xHG9oaBCeBtfLy2vBggUVFRXjxo1rU5dzFEUfPnwIbdpiJvaAwd9/UOerQYMG3b17NycnR/hAwmQCv08/AADgpiBpd3trRzuaAe/Ehu34X0F7pEA72tEOVzF06FAhzdskaZAwNE2Mzl026nQ6Ia8WOUU9D3C/JXiqVG1+LpnwJ7z00kstVUdpNllWS1nweTDACSKSFiW17tMMl/qqvLy87TgRExyt0r8DJ+34FXK5PC8vjyCI8PBwuVzODkBTWeTq2DTr1iVcQXdzc4uOjv7vqCAnznEFAODm5ga9cqEXhX3tGVHoO3yiVqudX662iri4uPPnz1ssluTkZO6tXDr7/26yBMOwl156SYTXeXt722w2GPd1586dFStW2H/rpF6Hq34FyC9QqVQmk2nlypWAb9H4wYMH4zhus9m4exdyAfxRrA8qjuNZWVlcGqIo6uoVGBw5mUzWs2dPs9l88uRJiZClqdVqdTodzEO5cuXKQYMGOUwNgTOFTVGFomhqaqrJZFq8ePHjx4937tx569Yt3mQzMzNpmrbZbKI4CUCkp6cfOXKEsQNN07W1tcIvy1jA3NIw//ahQ4dwHJ8xYwZBEHfu3LGPD2kRLT0BAHB3d9+1a1dVVdWBAweio6ObPglXJPfDH4IgcPA6d+785ptv3rt3r6GhwWKxlJeXw6vKiooKiqKsVquQKXLkyBGKosrLy0URgDDMCA4em1rWZrOVlZVlZGQkJiYKf8XUqVNv375NEARJkiRJ2mw2mE/61q1b0NNfkEs0AECtVpeXl3/22Wew0EDTfnHpujUvLw8OJIZhpaWlMBmsxWIhCMJsNtfW1l6/fh3DsCtXriQkJAjx+KqtrYUihDcFCJho0h4kSer1+qqqqh9//DE0NDQmJmbOnDkC3+Lr60uSJFziJpPJbDbD0jPff/+9TCa7d+/eqFGjCIJohVEnX0ml0vT09J9//lmn0wUFBTkcZj08PLp168Z9IGGJATiKn332GazUlJubu2vXrjFjxkCPCliiTaVSmc1m3oupT58+cIq89dZbDl+5usfAKg4QJpPp+vXro0aNWrx48aVLl6DYwHFcYGyCXC6HuYZhoZL9+/dPnTpVo9FotVqoz2MYJvSSPCws7OOPP37w4MGNGzdgBRMAgK+vb3JyMkVRBoNBKpWGhoY22+MOwlYmk2k0GsjN4MGDy8vLr1+/vnTpUqVSKZVKWS6blsdyFQAAeNVO07SD+/2pU6c6dOjAnVRKSgocQqPROGLECK1Wy86DEydOwIoDRqORCyknkTO7d+8mSdJsNs+cORPDMIVCERwcDAv82E87/vkuMQzbuHHjvn37KioqJkyYkJCQAGn169dPKpWypYRcQmBg4P79+2022/379/v27XvixIlx48bZZzAXfuzr1KkTdPb96KOPeJQNYSGTydi16OCfDcsVsxKF9ysAAKxkWrt2bWFhYVpaWlBQEPSiAwBw6o1WhyE2NvYvf/nLhx9+uGLFioCAAHd3dw8PD1hFkm3rql/CgQMHoNCDIcoURen1+r/97W9SqZTNcitQPUlJSYH7jUA6sC47lHjshIDeGP/6179Ylefhw4e8fc8TEhLsS4fD80xeXl5CQoKfn19AQIDz5r/mbnfyECxzER0dXV9fr9FoPDw8tFptUFAQLMDAtmVcTB7fo0eP+vp6s9lsNpunTZtWUlLy4MGD995779tvv71x40ZOTg5cBxypNYsJEyYAAO7cuSOQTkZGBqSAIIjJZIJued7e3l26dBkwYAAr9D7//HPevudHjx5lUwewS/zVV189d+7c5cuXRfD4RVHUy8srPz//1q1bR48etVqtcXFx7u7usJiuEMpNz6A+Pj4//vhjXV3d9evXYdS/kFcgCAKjgmBmcyGsoijKVoZl9VVWt2Q/FPIWDMNgiVs3NzcMwxITE1etWoXjOEVRBw8eFOF4GhAQcPr0aSj6oCTs06cPdKrjuIdxD/pRqVRz585NSEhISUnp3r27QKOiTCaDvSzWxcL333/P1juCvWE2m9mB7NevHxcizqsaQyMAZH7x4sW1tbV//etfXVLKmgcAIDs7e/ny5WfPntXr9ZDpvn378tYhJU5VGK1WW1pa+txzz4kSVvHGG29Ahnfu3CmcGgT8CdHR0QqFQqPRHD58GK5L3qKv2Z5EUdTPz+/QoUNms1mERGZQ1qWmpo4ZMyY5OXnJkiU4jpMkKfCopFQqmzX9AAD27duH4/jEiRNFMcFERETAgYTVUdsCU6dOhdJ13bp1/ChAzY79F8o5AMCYMWMIgtDpdEJVd7jGhw8f7uXlBQCQy+Vnz56laVqn03l7e/PoaHi6z8/P37Fjx8svvwxTUbG/QaFQ5OXlwY3H4ZzAe1C7du0qfOtyAhjVBF+xYcMGl9rC7aZ3794bNmzo0qWLwWBAEITdsI4fPw4tlEVFRYL4g3Bzc/v88887duwYEhLSr1+/yspKkiQLCwuhNYAHZWj3gco6SZLBwcFyuTwtLS0yMnLFihU//fRTdXW1iDG6UNlro1AbiUTSqVMnVs2B09QlwKUGJTNFUX/605+6du366aef7t69G8fxurq6JUuWiHD1CADIyMi4ePHiqlWrZs6ceffu3Xv37l27dm3nzp2wJDm/SyWZTAZZt9lsdXV1SUlJOp3OYDCYzWadTgdzFLTEj0svksvlcMbgOM5j2nFpYq+vukqffQs8cpAkaTAYXnjhBZg5jyTJTz75RHiMw78hk8k8PT2TkpIuXbq0adOmd955Jzo6OjMzMyQkRKvVtnT8aLULlEolrJLe2NhYU1MD42eNRuP48eNFdNUNDw+HHb19+/a2EK32dyAjRozgTUcmk0ETrslkqqiogHe9u3btcpVnZx1HEIRer7958+bevXtLS0tPnDih1+slEklWVpbVarVarc2eK1qdnhaLxcvLKzQ09NatWziOP3jwYNOmTXFxcQUFBSKKQTg/JBJJdXW1WDTtsXHjRravDx482NJjrY4HvJPat28frHE+b9684ODgtLQ0ESwALTEEY7I6dOjg5+cHP3F+JGqJTqufiAWtVtsmNYolEskvdc0heAsStjJzZGQkR88ScdyOngYvNziN/rPQaDRwCD09PQVGvNrfY/Do3qfQgbtFPA2zp63B/Tf+MXrjD8Fle2RdO9rRjtbw/6T2UG2O41iIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('92000.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN for MNIST Tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
